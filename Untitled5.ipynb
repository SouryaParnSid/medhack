{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b47fe590-de1a-425b-87ba-82330ee050f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras import Sequential\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import classification_report , confusion_matrix , accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2\n",
    "#from google.colab.patches import cv2_imshow\n",
    "from PIL import Image \n",
    "import tensorflow as tfl\n",
    "from keras.layers import Input, Dense,Conv2D , MaxPooling2D, Flatten,BatchNormalization,Dropout\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import tensorflow_hub as hub "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0894ca0a-3c4a-4679-beda-ac79772a8b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_path = \"Brain_Data_Organised/Normal\"  # Use forward slashes for better compatibility\n",
    "stroke_path = \"Brain_Data_Organised/Stroke\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb834459-cb83-4f3a-85d7-fffe8d279086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU:  1\n",
      "GPU Name:  NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name())\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7efaf0cb-511a-4ffb-b990-91609acb3bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0213de43-c6aa-4b51-9af6-4135c4f26ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Get filenames from each folder separately:\n",
    "normal_files = os.listdir(os.path.join(\"Brain_Data_Organised\", \"Normal\"))\n",
    "stroke_files = os.listdir(os.path.join(\"Brain_Data_Organised\", \"Stroke\"))\n",
    "\n",
    "data = []\n",
    "\n",
    "# Process normal images\n",
    "for img_file in normal_files:\n",
    "    image_path = os.path.join(\"Brain_Data_Organised\", \"Normal\", img_file)\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((224, 224))\n",
    "    image = image.convert('RGB')\n",
    "    data.append(image)\n",
    "\n",
    "# Process stroke images\n",
    "for img_file in stroke_files:\n",
    "    image_path = os.path.join(\"Brain_Data_Organised\", \"Stroke\", img_file)\n",
    "    image = Image.open(image_path)\n",
    "    image = image.resize((224, 224))\n",
    "    image = image.convert('RGB')\n",
    "    data.append(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dec630dc-9892-4a29-93d1-d67bdaaca960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1551\n",
      "2501\n"
     ]
    }
   ],
   "source": [
    "normal_label = [0]*len(normal_files)\n",
    "stroke_label = [1]*len(stroke_files)\n",
    "Target_label = normal_label + stroke_label\n",
    "print(len(normal_label))\n",
    "print(len(Target_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e64644ad-093b-4396-904a-a0191f2141db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "import albumentations as A\n",
    "from albumentations.core.composition import OneOf\n",
    "from albumentations.pytorch import ToTensorV2 \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "195c9730-1115-412c-a6c9-7e21cc9805d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# 🚀 1. Preprocess Data\n",
    "# =============================\n",
    "\n",
    "# Convert data & labels to numpy arrays\n",
    "x = np.array(data)\n",
    "y = np.array(Target_label)\n",
    "\n",
    "# Train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.10, random_state=42)\n",
    "\n",
    "# Normalize images\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Convert labels to categorical (one-hot encoding)\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# y_train = to_categorical(y_train, num_classes=2)\n",
    "# y_test = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "# Data Augmentation\n",
    "# Custom augmentation strategy\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,  # Controlled rotation to preserve diagnostic features\n",
    "    width_shift_range=0.05,  # Minor shifts to avoid cropping key features\n",
    "    height_shift_range=0.05,\n",
    "    zoom_range=0.08,  # Slight zoom, but not too aggressive\n",
    "    brightness_range=[0.85, 1.15],  # Keep contrast variation within realistic limits\n",
    "    horizontal_flip=False,  # Never flip medical images horizontally\n",
    "    fill_mode=\"reflect\",  # Avoid artificial border effects\n",
    "    shear_range=0.02,  # Very minimal shearing to preserve structure\n",
    "    channel_shift_range=0.1  # Subtle intensity variations similar to different CT machines\n",
    ")\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3313b1a-d8ff-472a-a0cc-c04b68d8f845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">72,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">46,144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43264</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">11,075,840</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │         \u001b[38;5;34m2,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m100\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m80\u001b[0m)   │        \u001b[38;5;34m72,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m80\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m46,144\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43264\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m11,075,840\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,229,889</span> (42.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,229,889\u001b[0m (42.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,229,889</span> (42.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,229,889\u001b[0m (42.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================\n",
    "# 📌 2. Define CNN Model\n",
    "# =============================\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Activation\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=100,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\", input_shape=(224,224,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=80,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),padding=\"valid\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=256, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "tf.config.optimizer.set_jit(True)\n",
    "# Build CNN model\n",
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11c1d15a-0719-4758-b86e-f398d0dc51ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29d84cb3-93f2-4343-a375-607647206ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'is_cuda_build': False, 'is_rocm_build': False, 'is_tensorrt_build': False, 'msvcp_dll_names': 'msvcp140.dll,msvcp140_1.dll'})\n"
     ]
    }
   ],
   "source": [
    "print(tf.sysconfig.get_build_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c74d36a-5cbf-438e-9ae5-72bc35b7eacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# 🔥 3. Load EfficientNet Model\n",
    "# =============================\n",
    "\n",
    "efficientnet = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "efficientnet = tf.keras.Model(inputs=efficientnet.input, outputs=GlobalAveragePooling2D()(efficientnet.output))\n",
    "\n",
    "def extract_features(model, data):\n",
    "    features = model.predict(data,  batch_size=32)\n",
    "    return features.reshape(features.shape[0], -1)  # Flatten features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b1c6785-a329-4aa7-834a-4ddd36ec24c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 829ms/step - accuracy: 0.6254 - loss: 0.6742 - val_accuracy: 0.5936 - val_loss: 0.6791 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 805ms/step - accuracy: 0.6204 - loss: 0.6661 - val_accuracy: 0.5936 - val_loss: 0.6770 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 802ms/step - accuracy: 0.6109 - loss: 0.6746 - val_accuracy: 0.5936 - val_loss: 0.6701 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 802ms/step - accuracy: 0.6344 - loss: 0.6551 - val_accuracy: 0.6016 - val_loss: 0.6587 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 797ms/step - accuracy: 0.6122 - loss: 0.6685 - val_accuracy: 0.5936 - val_loss: 0.6757 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 809ms/step - accuracy: 0.6252 - loss: 0.6580 - val_accuracy: 0.5936 - val_loss: 0.6723 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771ms/step - accuracy: 0.6309 - loss: 0.6602\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 794ms/step - accuracy: 0.6308 - loss: 0.6602 - val_accuracy: 0.5936 - val_loss: 0.6691 - learning_rate: 0.0010\n",
      "Epoch 7: early stopping\n",
      "Restoring model weights from the end of the best epoch: 4.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32,), but the yielded element was [[[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]\n\n\n [[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]\n\n\n [[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]\n\n\n ...\n\n\n [[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]\n\n\n [[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]\n\n\n [[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]].\nTraceback (most recent call last):\n\n  File \"D:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 204, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"D:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py\", line 237, in flatten_up_to\n    return nest_util.flatten_up_to(\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"D:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\util\\nest_util.py\", line 1541, in flatten_up_to\n    return _tf_data_flatten_up_to(shallow_tree, input_tree)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"D:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\util\\nest_util.py\", line 1570, in _tf_data_flatten_up_to\n    _tf_data_assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"D:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\util\\nest_util.py\", line 1414, in _tf_data_assert_shallow_structure\n    raise TypeError(\n\nTypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: 'ndarray'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"D:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"D:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"D:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 206, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32,), but the yielded element was [[[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]\n\n\n [[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]\n\n\n [[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]\n\n\n ...\n\n\n [[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]\n\n\n [[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]\n\n\n [[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]].\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 16\u001b[0m\n\u001b[0;32m     10\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(datagen\u001b[38;5;241m.\u001b[39mflow(x_train, y_train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m),\n\u001b[0;32m     11\u001b[0m                         epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m     12\u001b[0m                         validation_data\u001b[38;5;241m=\u001b[39m(x_test, y_test),\n\u001b[0;32m     13\u001b[0m                         callbacks\u001b[38;5;241m=\u001b[39m[early_stopping, lr_scheduler])\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Extract CNN Features\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m cnn_features_train \u001b[38;5;241m=\u001b[39m extract_features(model, datagen\u001b[38;5;241m.\u001b[39mflow(x_train))\n\u001b[0;32m     17\u001b[0m cnn_features_test \u001b[38;5;241m=\u001b[39m extract_features(model, x_test)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Extract EfficientNet Features\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 9\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(model, data)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_features\u001b[39m(model, data):\n\u001b[1;32m----> 9\u001b[0m     features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(data,  batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m features\u001b[38;5;241m.\u001b[39mreshape(features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6002\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   6001\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 6002\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_1_device_/job:localhost/replica:0/task:0/device:CPU:0}} TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32,), but the yielded element was [[[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]\n\n\n [[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]\n\n\n [[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]\n\n\n ...\n\n\n [[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]\n\n\n [[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]\n\n\n [[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]].\nTraceback (most recent call last):\n\n  File \"D:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 204, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"D:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py\", line 237, in flatten_up_to\n    return nest_util.flatten_up_to(\n           ^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"D:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\util\\nest_util.py\", line 1541, in flatten_up_to\n    return _tf_data_flatten_up_to(shallow_tree, input_tree)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"D:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\util\\nest_util.py\", line 1570, in _tf_data_flatten_up_to\n    _tf_data_assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"D:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\util\\nest_util.py\", line 1414, in _tf_data_assert_shallow_structure\n    raise TypeError(\n\nTypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: 'ndarray'.\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"D:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"D:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"D:\\anaconda\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\from_generator_op.py\", line 206, in generator_py_func\n    raise TypeError(\n\nTypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32,), but the yielded element was [[[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]\n\n\n [[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]\n\n\n [[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]\n\n\n ...\n\n\n [[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]\n\n\n [[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]\n\n\n [[[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  ...\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]\n\n  [[0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]\n   ...\n   [0. 0. 0.]\n   [0. 0. 0.]\n   [0. 0. 0.]]]].\n\n\n\t [[{{node PyFunc}}]] [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# 🔄 4. Train Both Models & Extract Features\n",
    "# =============================\n",
    "\n",
    "# Define Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True,verbose=1)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=3)\n",
    "\n",
    "# Train CNN model\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=32),\n",
    "                        epochs=50,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "# Extract CNN Features\n",
    "cnn_features_train = extract_features(model, datagen.flow(x_train))\n",
    "cnn_features_test = extract_features(model, x_test)\n",
    "\n",
    "# Extract EfficientNet Features\n",
    "efficientnet_features_train = extract_features(efficientnet,  datagen.flow(x_train))\n",
    "efficientnet_features_test = extract_features(efficientnet, x_test)\n",
    "\n",
    "# Concatenate CNN & EfficientNet features\n",
    "X_train_meta = np.hstack((cnn_features_train, efficientnet_features_train))\n",
    "X_test_meta = np.hstack((cnn_features_test, efficientnet_features_test))\n",
    "\n",
    "#Convert one-hot labels to single-class labels\n",
    "# y_train_meta = np.argmax(y_train, axis=1)\n",
    "# y_test_meta = np.argmax(y_test, axis=1)\n",
    "y_train_meta = y_train\n",
    "y_test_meta = y_test\n",
    "\n",
    "loss, acc = model.evaluate(x_test,y_test)\n",
    "print(\"Loss on Test Data:\",loss)\n",
    "print(\"Accuracy on Test Data:\",acc)\n",
    "\n",
    "loss, acc = model.evaluate(x_train,y_train)\n",
    "print(\"Loss on Train Data:\",loss)\n",
    "print(\"Accuracy on Train Data:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c83290-faad-4360-b8b7-119f2e8e0266",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================\n",
    "# 🏆 5. Hyperparameter Tuning with RandomizedSearchCV for XGBoost\n",
    "# =============================\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', tree_method='gpu_hist')\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'gamma': [0, 0.1, 0.3]\n",
    "}\n",
    "\n",
    "# Perform Randomized Search\n",
    "random_search = RandomizedSearchCV(xgb_model, param_distributions=param_dist, cv=5, scoring='accuracy', verbose=3, n_jobs=4, n_iter=10, random_state=42)\n",
    "random_search.fit(X_train_meta, y_train_meta)\n",
    "\n",
    "# Best XGBoost model\n",
    "best_xgb = random_search.best_estimator_\n",
    "\n",
    "# Predict & Evaluate\n",
    "y_pred = best_xgb.predict(X_test_meta)\n",
    "accuracy = accuracy_score(y_test_meta, y_pred)\n",
    "\n",
    "print(f\"🏆 Best XGBoost Hyperparameters: {random_search.best_params_}\")\n",
    "print(f\"🎯 Tuned Ensemble Model Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7139218c-403b-4823-b552-04eecb6d418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# 📊 6. Performance Metrics\n",
    "# =============================\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import seaborn as sns\n",
    "\n",
    "# =============================\n",
    "# 🎯 6. Evaluate Model Performance\n",
    "# =============================\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(y_test_meta, y_pred)\n",
    "print(f\"🎯 Tuned Ensemble Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Classification Report (Precision, Recall, F1-score)\n",
    "print(\"\\n📄 Classification Report:\\n\")\n",
    "print(classification_report(y_test_meta, y_pred, target_names=[\"Normal\", \"Stroke\"]))\n",
    "\n",
    "# =============================\n",
    "# 📌 7. Confusion Matrix\n",
    "# =============================\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(confusion_matrix(y_test_meta, y_pred), annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Normal\", \"Stroke\"], yticklabels=[\"Normal\", \"Stroke\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# =============================\n",
    "# 📈 8. ROC Curve (AUC-ROC)\n",
    "# =============================\n",
    "\n",
    "# Get probability scores for ROC Curve\n",
    "y_pred_probs = best_xgb.predict_proba(X_test_meta)[:, 1]  # Probabilities for positive class (Stroke)\n",
    "\n",
    "# Compute ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test_meta, y_pred_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f\"AUC = {roc_auc:.2f}\")\n",
    "plt.plot([0,1], [0,1], 'r--')  # Diagonal line (random classifier)\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Plot Loss Function\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Function Over Epochs')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Assuming you have trained your CNN and have a 'history' object from model.fit()\n",
    "# e.g., history = model.fit(...)\n",
    "\n",
    "# Extract accuracy values from the history object\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']  # If you used a validation set\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "# Plotting the training and validation accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epochs, accuracy, 'bo-', label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'r*-', label='Validation Accuracy')\n",
    "plt.title('Epoch vs. Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(visible=True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02335b61-674b-41e7-884d-6027955a933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Function to visualize images with actual & predicted labels\n",
    "def visualize_predictions(images, actual_labels, predicted_labels, num_images=10, title=\"Predictions\"):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        idx = random.randint(0, len(images) - 1)  # Randomly select an image\n",
    "\n",
    "        plt.subplot(2, 5, i + 1)\n",
    "        plt.imshow(images[idx])  # Show the image\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Set title with actual & predicted labels\n",
    "        actual = \"Stroke\" if actual_labels[idx] == 1 else \"No Stroke\"\n",
    "        predicted = \"Stroke\" if predicted_labels[idx] == 1 else \"No Stroke\"\n",
    "        \n",
    "        title_color = \"green\" if actual == predicted else \"red\"  # Green = correct, Red = wrong\n",
    "        plt.title(f\"Actual: {actual}\\nPred: {predicted}\", color=title_color)\n",
    "\n",
    "    plt.suptitle(title, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Get predictions for test images\n",
    "y_test_pred = best_xgb.predict(X_test_meta)\n",
    "\n",
    "# Visualize train images\n",
    "visualize_predictions(x_train, y_train, best_xgb.predict(X_train_meta), title=\"Train Set Predictions\")\n",
    "\n",
    "# Visualize test images\n",
    "visualize_predictions(x_test, y_test, y_test_pred, title=\"Test Set Predictions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1a4392-2191-4242-aad4-2b9c7b820fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c708c24-0bd2-4528-861e-7758039ab91c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
